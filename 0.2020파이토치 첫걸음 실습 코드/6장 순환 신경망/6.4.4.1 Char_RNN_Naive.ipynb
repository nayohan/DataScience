{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LEMD4f9dG3U"
   },
   "source": [
    "# Character Recurrent Neural Network\n",
    "- 셰익스피어 문체를 모방하는 순환신경망 실습 코드입니다.\n",
    "- Embedding 레이어 및 RNN 모델로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgYi5hIIkjOg"
   },
   "source": [
    "## 데이터를 먼저 준비해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13495,
     "status": "ok",
     "timestamp": 1559553888332,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "ODxhI-YBeYKz",
    "outputId": "92de6e7c-9200-41f5-bcba-27b70117970a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!rm -r data\n",
    "import os \n",
    "\n",
    "try:\n",
    "  os.mkdir(\"./data\")\n",
    "except:\n",
    "  pass\n",
    "\n",
    "#!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0FyjLatdG3V"
   },
   "source": [
    "## 1. Settings\n",
    "### 1) 필요한 라이브러리들을 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVeUr2FjdG3X"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18418,
     "status": "ok",
     "timestamp": 1559553893279,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "guzyAtUZPWj3",
    "outputId": "bde65b41-883b-4c94-adbc-d43e9a535102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\public\\anaconda3\\lib\\site-packages (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\public\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwWbv_-KdG3a"
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62S5HbY2dG3d"
   },
   "source": [
    "## 2) Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVeZybezdG3e"
   },
   "outputs": [],
   "source": [
    "#num_epochs = 2000\n",
    "num_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "\n",
    "# chunk에 대한 설명은 아래 함수정의하면서 하겠습니다.\n",
    "chunk_len = 200\n",
    "\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "num_layers = 1\n",
    "embedding_size = 70\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_eKGWH4BdG3h"
   },
   "source": [
    "## 2. Data\n",
    "### 1) Prepare characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18406,
     "status": "ok",
     "timestamp": 1559553893284,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "2Cg5-Wp0dG3i",
    "outputId": "3184b0dc-bdd5-4f6e-b975-852c6f591572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "# import 했던 string에서 출력가능한 문자들을 다 불러옵니다. \n",
    "all_characters = string.printable\n",
    "\n",
    "# 출력가능한 문자들의 개수를 저장해놓습니다.\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AxeLPVWsdG3m"
   },
   "source": [
    "### 2) Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18399,
     "status": "ok",
     "timestamp": 1559553893285,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "5LEkE0bxdG3n",
    "outputId": "1e0f0d9d-5e3f-4e2b-cdff-8109675bd492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 33756\n"
     ]
    }
   ],
   "source": [
    "# 앞서 다운받은 텍스트 파일을 열어줍니다.\n",
    "\n",
    "#file = unidecode.unidecode(open('./data/input.txt').read())\n",
    "file = unidecode.unidecode(open('./data/linux.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmTf-IBOdG3r"
   },
   "source": [
    "## 3. Functions for text processing\n",
    "### 1) Random Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18389,
     "status": "ok",
     "timestamp": 1559553893285,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "bXDt_MmzdG3s",
    "outputId": "25a24ecd-18ef-4343-ee37-29ba09909e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fq_group *bfqg,\n",
      "\t\t\t\t\tstruct bfq_group *parent)\n",
      "{\n",
      "\tstruct bfq_entity *entity;\n",
      "\n",
      "\tentity = &bfqg->entity;\n",
      "\tentity->parent = parent->my_entity;\n",
      "\tentity->sched_data = &parent->sched_data;\n",
      "}\n",
      "\n",
      "static struct b\n"
     ]
    }
   ],
   "source": [
    "# 이 함수는 텍스트 파일의 일부분을 랜덤하게 불러오는 코드입니다.\n",
    "def random_chunk():\n",
    "    # (시작지점 < 텍스트파일 전체길이 - 불러오는 텍스트의 길이)가 되도록 시작점과 끝점을 정합니다.\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsSgzWIRdG3v"
   },
   "source": [
    "### 2) Character to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18382,
     "status": "ok",
     "timestamp": 1559553893286,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "fhY5WxwsdG3v",
    "outputId": "912cc446-a4ef-42ee-a865-130c18144fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36, 37, 38, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "# 문자열을 받았을때 이를 인덱스의 배열로 바꿔주는 함수입니다.\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Boc9LQimdG3y"
   },
   "source": [
    "### 3) Chunk into input & label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDoMmRY2dG3z"
   },
   "outputs": [],
   "source": [
    "# 랜덤한 텍스트 chunk를 불러와서 이를 입력과 목표값을 바꿔주는 함수입니다.\n",
    "# 예를 들어 pytorch라는 문자열이 들어오면 입력은 pytorc / 목표값은 ytorch 가 됩니다.\n",
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsHsRxlodG31"
   },
   "source": [
    "## 3. Model & Optimizer\n",
    "### 1) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94ku2mreuAVn"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # 임베딩 함수에 대한 설명은 책과 공식 도큐먼트를 참고하시길 바랍니다.\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding\n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.rnn = nn.RNN(self.embedding_size,self.hidden_size,self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,hidden = self.rnn(out,hidden)\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        return out,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "    \n",
    "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "teNVxi0cPgi5"
   },
   "outputs": [],
   "source": [
    "model = RNN(input_size=n_characters, \n",
    "            embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size, \n",
    "            output_size=n_characters, \n",
    "            num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18891,
     "status": "ok",
     "timestamp": 1559553893810,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "rOVPmyxodG37",
    "outputId": "b3f31d2f-27f2-4a27-cd58-acec0b8f682e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36])\n",
      "torch.Size([2, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트 \n",
    "\n",
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())\n",
    "out,hidden = model(inp,hidden)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfpAh13edG3_"
   },
   "source": [
    "### 2) Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wRW02JXdG3_"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoiLqf3_dG4C"
   },
   "source": [
    "### 3) Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rVTQky8vdG4D"
   },
   "outputs": [],
   "source": [
    "# 임의의 문자(start_str)로 시작하는 길이 200짜리 모방 글을 생성하는 코드입니다.\n",
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden = model(x,hidden)\n",
    "\n",
    "        # 여기서 max값을 사용하지 않고 multinomial을 사용하는 이유는 만약 max 값만 쓰는 경우에\n",
    "        # 생성되는 텍스트가 다 the the the the the 이런식으로 나오기 때문입니다.\n",
    "        # multinomial 함수를 통해 높은 값을 가지는 문자들중에 램덤하게 다음 글자를 뽑아내는 방식으로 자연스러운 텍스트를 생성해냅니다.\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNaIweaudG4G"
   },
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3301
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 293566,
     "status": "ok",
     "timestamp": 1559554168504,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "6CnV3_andG4H",
    "outputId": "e981b5be-625b-45ba-963a-94a8c71f6c97",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([4.6083], grad_fn=<DivBackward0>) \n",
      "\n",
      "b'0inL\n",
      "|lZ4FUYp[[SqCsBSs^2ZDS:CF'@-9EbTE*B,#Q/.JV\t cO9wdZ}ry\u000b",
      "KsD\u000b",
      "l?vZ\n",
      "-UM;>yc'PEG:}r,bnI*}o`l/fdL,O\n",
      "->n-9Gm\t\u000b",
      "y7=%_Aqmd;3b$sT@\n",
      ">.=EToqqoRlIgf{>_9]~}\n",
      "?6^@u_%Y7~`nY[c;aftb;b=q|Q&aqS#mlmb3x[OA]N&)jUo6J\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9737], grad_fn=<DivBackward0>) \n",
      "\n",
      "bbkqW->statt_ime.stats olstluct bfqg->entfe_entrt iscint_tiint *ofq_tare Fstatre(statstit1 * *bfqg_stount bfqg->strtj g &of bfq_grountity Tstatstlic, blkg_(stats_fqq;\n",
      "\t *Ffqg->sti/_tart_iteuct_ofN);\n",
      "\tr\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.5776], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqgg(pating cfod sf);\n",
      "\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\tala ang(stats_to_waLt, cod(st bfq_entity_ifd);\n",
      "\t\tin_alater (bfq->ser_int) *pdscatved_vog(stats *;\n",
      "\t\tint bgroue *bfq_entity, bfq_grockgshentaasg to_pevoin &bfqg);\n",
      "\t\t\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.5786], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg)\n",
      "{\n",
      "\tstqueuet the tie, voi_soke_size _blkg_stats oreet abe bfq_group vo_bfqg->stats *f lent_to_blkg_bfq_group *bfqg_stats, the stats_queue_lic_bfqg_powicy_statsinit_u64 sestme th bfq_queue_size_sta\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.1545], grad_fn=<DivBackward0>) \n",
      "\n",
      "byct(sf)));\n",
      "\tstat * fils = BFQGG(&of gst *reupve_sive(sin_time, io ffice ce blkg_stats)\n",
      "\t\t\t\t\t\t\t * lentity, stats_updion *p, in { = blkcg_print_stats_detat_serocurvet_stats_67ig vore And vavaty_updace_t\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([0.7777], grad_fn=<DivBackward0>) \n",
      "\n",
      "blkg_stats_idlive(stats->ceructed the canse_size_size_sfqg_stats_edate *stats_woig_prin;\n",
      "\tstruct bfq)(&stats_entity_wats_time))\n",
      "\t\tbfqq->ivate = ong gfp, int bfq_emt_blkg);\n",
      "}\n",
      "\n",
      "sicae new thit blkg_policy\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([0.6347], grad_fn=<DivBackward0>) \n",
      "\n",
      "blkg = \"blkg re->gentity to retore);\n",
      "\n",
      "\n",
      "\tbfqg->entity->meq_pd_allen in beq *bfqg)\n",
      "{\n",
      "\tstruct if (stats *bfqg, bfqg->stats;\n",
      "\n",
      "/*/\n",
      "/* Tho mer asssgroup_woiae nal blkcg_to_inarer in blkg_private canser it th\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.0773], grad_fn=<DivBackward0>) \n",
      "\n",
      "blkg) ||\n",
      "\t     reued loch sequeles nonide leat be alling blkg this reath |rom whis bfqg_private &stats->queue_sizessvowe);\n",
      "\tif (blkg_stats_sum);\n",
      "\t\t\t        void bfq_iped <(pd)h);\n",
      "}\n",
      "\n",
      "statit_clats.new_we\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.7771], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfq_entity_blkcg(service_time);\n",
      "\tblkcg_policy bio->entity(struct sonnc */\n",
      "static -hstags \"/\n",
      "\n",
      "void bfq_reparent_bfqq(struct bfq_group *bicg = N;\n",
      "}\n",
      "\n",
      "struct bfq_group <blkg_add_entity *f the on bfqd, blkg\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.4133], grad_fn=<DivBackward0>) \n",
      "\n",
      "blkg_stat_reset(&stats->start_time);\n",
      "\tentity;\n",
      "\n",
      "\tblkg_stat_reset(&stats->marq_idle_time),\n",
      "\t\tin io the foll be ure an the &bfqg->sfart(&start_time);\n",
      "\treturn 0;\n",
      "\tblkg_rwstat_repd_allo_byg_to_bfqqg)\n",
      "{\n",
      "\tstr\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.2095], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg->stats->avg_queue_size(struct bfq_group. Cpdate *bfqg);\n",
      "\t{\n",
      "\t\t.private *stats *pinations off)) { }\n",
      "/* If (unait_bic_blkcg(seq_pd_blkcg(surd(struct bfq_group(struct bfqg_stats_update_sex(&stats = bf\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.4868], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg->stats->service_time\",\n",
      "\t\t.prix_time(struct bfq_group *bfqg) {\n",
      "\t\t\troup, stats.mark_is_unf AN64_WEIGHT_NULL,\n",
      "\t\t.name = \"bfq.io_queue);\n",
      "\t/*\n",
      "\t\t * the prio_class(bfqg);\n",
      "\n",
      "\tlock he reee the blkg_rwstat_r\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([0.4238], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg;\n",
      "\n",
      "\tblkg_stat_exit(&stats);\n",
      "\t\treturn 0;\n",
      "}\n",
      "\n",
      "static void bfqg_stats_emd(&bfqg->stats);\n",
      "}\n",
      "\n",
      "/* @!of rever that weight the for the blkgd to the root group entity->weight,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   * bfq_data *bf\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([0.6223], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqd,\n",
      " * @bfqd = bfqg_stats *stats))\n",
      "{\n",
      "\tif (rentity);\n",
      "\n",
      "\tseued reued),\n",
      "\t\t\t\t      of) ||\n",
      "\t   parent_stat_reset(&blkcg_policy_cnoight lestrent, the blkg_stats *stats);\n",
      "\tstruct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct b\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([0.6526], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg_prfill_ser_cgroup_waiting(stats;\n",
      "\t}\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t/*\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbfqg_stats_cfqq->new_iopactivating the contine bfqd->lock.\n",
      " * = bfq_entity = bfqq->new_idle_time = bfqq_show = bfqg_priok(inte\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([0.4311], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg_stats_update_idee, struct bfq_desched_clock();\n",
      "\tbfqg) { }\n",
      "void bfq_entity.now_lear_init *st, struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqq,\n",
      "\t\treturn bfqg,\n",
      "\t\t * to the pd_to_bfqgd(entity)\n",
      "\t\tbfq\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.7209], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfq.sut_seq_group_wait_time(stats))\n",
      "\t\tbfqg_stats_unlock_lead(&bfqg)->start_group(struct bfq_queue *root_group_waiting)\n",
      "\t\tbfqg_stats_end_w = (unsigned int op io for ho mhais soves.\n",
      " * @parent;\n",
      "\n",
      "\treturn \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([0.3907], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg_stats_entity);\n",
      "\treturn (stats = &bfqg_stats_update_set_sempty_time)) W*\n",
      "\t * leting the origes (stats, ald tree ofld bfq_entity->oly of te cathe the entity the semplend int of In bfq_blkg_staty *st\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([0.4302], grad_fn=<DivBackward0>) \n",
      "\n",
      "blkg_rwstat_idle_triohe tracting been bfqg and blk.  of the not to stovel to start = bfqg_prong plites.\n",
      "\t */\n",
      "\t\tif (bfqg->bfqgd)\n",
      "{\n",
      "\tstruct bfq_group *bfqg)\n",
      "{\n",
      "\t/* dinal blkg bfqd thele along new we not\t \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([0.6653], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg)\n",
      "{\n",
      "\tstruct bfq_group.\n",
      " * @bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg = blQg_rwstat(struct bfq_entity_weight *entity->blkg).\n",
      "\t\t\treturn &from->wate false\n",
      "\t * this (struct bfq_group *bfqg = bfqq that heluvo _se\n",
      " ====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    # 랜덤한 텍스트 덩어리를 샘플링하고 이를 인덱스 텐서로 변환합니다. \n",
    "    inp,label = random_training_set()\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y,hidden = model(x,hidden)\n",
    "        loss += loss_func(y,y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\",\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6.4.4.1 Char_RNN_Naive.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
