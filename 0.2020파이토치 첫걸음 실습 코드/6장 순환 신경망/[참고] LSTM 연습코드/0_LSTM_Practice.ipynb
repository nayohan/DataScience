{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_14gXaT9gN-"
   },
   "source": [
    "# LSTM Practice\n",
    "## 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5933,
     "status": "ok",
     "timestamp": 1559546120291,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "5YflIP-G9n2L",
    "outputId": "f2b4bb98-c03d-43b0-a5fb-121f2bd245fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbSmqYOX9gOA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtAGFi5m9gOE"
   },
   "source": [
    "### 2) Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6201,
     "status": "ok",
     "timestamp": 1559546120589,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "0lfCkLo_9gOE",
    "outputId": "1c42ced1-3c14-4a3d-99d5-23fe1369b21a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 5]) torch.Size([2, 3, 5]) torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM\n",
    "# input_size:     입력의 특성 개수\n",
    "# hidden_size:    hidden state의 특성 개수\n",
    "# num_layers:     LSTM을 몇층으로 쌓을것인가 여부\n",
    "# bias:           편차의 사용 여부\n",
    "# batch_first:    사용하면 입력과 출력의 형태가 [batch, seq, feature]\n",
    "# dropout:        드롭아웃 사용여부\n",
    "# bidirectional:  참고 http://solarisailab.com/archives/1515\n",
    "\n",
    "rnn = nn.LSTM(input_size=3, hidden_size=5, num_layers=2)\n",
    "\n",
    "# 기본적으로 입력의 형태는 (seq_len, batch, input_size)를 따릅니다.\n",
    "input_ = torch.randn(5, 3, 3)\n",
    "\n",
    "# hidden state, cell state의 형태는 (num_layers * num_directions, batch, hidden_size)를 따릅니다.\n",
    "h0 = torch.randn(2, 3, 5)\n",
    "c0 = torch.randn(2, 3, 5)\n",
    "\n",
    "# LSTM에 입력을 전달할때는 input, (h_0, c_0) 처럼 상태를 튜플로 묶어서 전달합니다.\n",
    "output, (hidden_state, cell_state) = rnn(input_, (h0, c0))\n",
    "\n",
    "print(output.size(),hidden_state.size(),cell_state.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rRvJjx6y9gOH"
   },
   "source": [
    "### 3) Hard coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6170,
     "status": "ok",
     "timestamp": 1559546120590,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "VPl8F-o79gOI",
    "outputId": "83e1976a-e68c-4e32-f7bf-20796c44e9f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 3]) torch.Size([2, 3, 5]) torch.Size([2, 3, 5])\n",
      "torch.Size([3, 5, 5]) torch.Size([2, 3, 5]) torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# 이번엔 batch_first를 한번 사용해보겠습니다.\n",
    "# \n",
    "\n",
    "rnn = nn.LSTM(3, 5, 2, batch_first=True)\n",
    "\n",
    "# batch_first를 사용하면 입력의 형태는 (batch, seq, feature)로 받게 됩니다.\n",
    "input_ = torch.randn(3, 5, 3)\n",
    "\n",
    "# hidden state, cell state의 형태는 동일하게 (num_layers * num_directions, batch, hidden_size)를 따릅니다.\n",
    "h0 = torch.randn(2, 3, 5)\n",
    "c0 = torch.randn(2, 3, 5)\n",
    "\n",
    "# LSTM에 입력을 전달할때는 동일하게 input, (h_0, c_0) 처럼 상태를 튜플로 묶어서 전달합니다.\n",
    "output, (hidden_state, cell_state) = rnn(input_, (h0, c0))\n",
    "\n",
    "print(input_.size(),h0.size(),c0.size())\n",
    "print(output.size(),hidden_state.size(),cell_state.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYvfFCG89gON"
   },
   "source": [
    "### 4) With parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6156,
     "status": "ok",
     "timestamp": 1559546120591,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "Up0HgvEV9gON",
    "outputId": "ffbb77a4-63b2-4156-b29a-dc8eaedbc168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 7]) torch.Size([2, 4, 3]) torch.Size([2, 4, 3])\n",
      "torch.Size([4, 3, 3]) torch.Size([2, 4, 3]) torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# 숫자로 하드코딩하는건 안 좋은 방법이기 때문에 이를 하이퍼파라미터 변수로 설정하는게 좋습니다.\n",
    "\n",
    "input_size = 7\n",
    "batch_size = 4\n",
    "hidden_size = 3\n",
    "seq_len = 2\n",
    "\n",
    "rnn = nn.LSTM(input_size, hidden_size, seq_len, batch_first=True)\n",
    "\n",
    "input_ = torch.randn(batch_size, hidden_size, input_size)\n",
    "h0 = torch.randn(seq_len, batch_size, hidden_size)\n",
    "c0 = torch.randn(seq_len, batch_size, hidden_size)\n",
    "\n",
    "output, (hidden_state, cell_state) = rnn(input_, (h0, c0))\n",
    "\n",
    "print(input_.size(),h0.size(),c0.size())\n",
    "print(output.size(),hidden_state.size(),cell_state.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulgKrnCY_IRW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "0_LSTM_Practice.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
