{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOuZCNJbgO8M"
   },
   "source": [
    "# 컨볼루션 인공신경망 Convolutional Neural Network\n",
    "- MNIST 데이터\n",
    "- 합성곱 연산(CNN) \n",
    "- 맥스풀링(Max Pooling)\n",
    "- 완전연결 신경망(Fully Connected Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5378,
     "status": "ok",
     "timestamp": 1566788509621,
     "user": {
      "displayName": "Gunho Choi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBSqM0cFU5ZceEDo5gH8hXfSGh8z5BVTu5HgREceg=s64",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "vFXzochygZn4",
    "outputId": "43b872a3-0021-4535-8d51-965f9587737c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\public\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\public\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: future in c:\\users\\public\\anaconda3\\lib\\site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\public\\anaconda3\\lib\\site-packages (from torch) (1.18.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\public\\anaconda3\\lib\\site-packages (from torchvision) (7.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\public\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# 파이토치 및 토치비젼 설치\n",
    "# 런타임을 GPU 모드로 바꿔서 실행하세요\n",
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlMbbW9BgO8O"
   },
   "source": [
    "## 1. 학습전 세팅\n",
    "### 1) 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1566788569851,
     "user": {
      "displayName": "Gunho Choi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBSqM0cFU5ZceEDo5gH8hXfSGh8z5BVTu5HgREceg=s64",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "whIeu56bgO8P",
    "outputId": "e2b012e4-39ff-47d7-8e4d-dc92ab8cee66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "# https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "# 파이토치에서는 torchvision.datasets에 MNIST 등의 다양한 데이터를 사용하기 용이하게 정리해놨습니다.\n",
    "# 이를 사용하면 데이터를 따로 학습에 맞게 정리하거나 하지 않아도 바로 사용이 가능합니다.\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "# https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transforms\n",
    "# torchvision.transforms에는 이미지 데이터를 자르거나 확대 및 다양하게 변형시키는 함수들이 구현되어 있습니다. \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader\n",
    "# DataLoader는 전처리가 끝난 데이터들을 지정한 배치 크기에 맞게 모아서 전달해주는 역할을 합니다.\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lt5vZrEUgO8U"
   },
   "source": [
    "### 2) 하이퍼파라미터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUACXvs4gO8W"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2fUKQiugO8a"
   },
   "source": [
    "## 2. 데이터\n",
    "\n",
    "### 1) 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epKZyEd5gO8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ../\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=mnist#torchvision.datasets.MNIST\n",
    "# 첫번째 인자 root는 데이터를 저장할 위치, train은 학습용 데이터인지 테스트용 데이터인지의 여부를 의미합니다.\n",
    "\n",
    "# MNIST 데이터는 숫자 손글씨 이미지와 이에 대한 정답 쌍으로 이루어져 있습니다. \n",
    "# transform은 이미지에 대한 변형, target_transform은 정답 라벨에 대한 변형을 의미합니다.\n",
    "# transform.ToTensor()는 PIL 이미지나 Numpy 배열을 토치 텐서로 바꿔줍니다.\n",
    "\n",
    "# download는 데이터가 저장할 위치에 없을 경우 새로 다운받을지 여부입니다.\n",
    "mnist_train = dset.MNIST(root=\"../\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_test = dset.MNIST(root=\"../\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "print(mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMKE4poIgO8e"
   },
   "source": [
    "### 2) 데이터셋 체크\n",
    "- getitem을 사용해도 되고 \n",
    "- 인덱싱으로도 데이터를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1083,
     "status": "ok",
     "timestamp": 1566788657322,
     "user": {
      "displayName": "Gunho Choi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBSqM0cFU5ZceEDo5gH8hXfSGh8z5BVTu5HgREceg=s64",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "Bb4OXGWIgO8f",
    "outputId": "d9f6fc5f-b0be-433a-c3fb-ea145e3d0c27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 60000\n",
      "torch.Size([1, 28, 28]) 10000\n",
      "60000 10000\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ../\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train.__getitem__(0)[0].size(), mnist_train.__len__())\n",
    "print(mnist_test.__getitem__(0)[0].size(), mnist_test.__len__())\n",
    "\n",
    "print(len(mnist_train),len(mnist_test))\n",
    "\n",
    "print(mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwfoDvZugO8m"
   },
   "source": [
    "### 3) DataLoader 설정\n",
    "- 사용할 데이터\n",
    "- 배치 사이즈 (batch_size)\n",
    "- 섞을지 여부 (shuffle)\n",
    "- 사용할 프로세스 개수 (num_workers)\n",
    "- 마지막에 남는 데이터의 처리 여부 (drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVXTTAtqgO8o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000017EDC415848>\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader\n",
    "\n",
    "train_loader = DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
    "test_loader = DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tf-jvTNggO8r"
   },
   "source": [
    "## 3. 모델, 손실함수, 최적화함수\n",
    "\n",
    "### 1) CNN 모델\n",
    "\n",
    "- Sequential 에 대한 설명은 4장에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q2gmbH3AgO8t"
   },
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d\n",
    "# https://pytorch.org/docs/stable/tensors.html?highlight=view#torch.Tensor.view\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5),             # [batch_size,1,28,28] -> [batch_size,16,24,24]\n",
    "            nn.ReLU(),                                                          # 필터의 개수는 1개(흑백이미지)에서 16개로 늘어나도록 임의로 설정했습니다. \n",
    "            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5),            # [batch_size,16,24,24] -> [batch_size,32,20,20]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),                               # [batch_size,32,20,20] -> [batch_size,32,10,10]\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),          # [batch_size,32,10,10] -> [batch_size,64,6,6]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)                                # [batch_size,64,6,6] -> [batch_size,64,3,3]\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(                                          \n",
    "            nn.Linear(64*3*3,100),                                              # [batch_size,64*3*3] -> [batch_size,100]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)                                                   # [batch_size,100] -> [batch_size,10]\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)                                                     # self.layer에 정의한 Sequential의 연산을 차례대로 다 실행합니다.\n",
    "        out = out.view(batch_size,-1)                                           # view 함수를 이용해 텐서의 형태를 [batch_size,나머지]로 바꿔줍니다. \n",
    "                                                                                # ex) 2x3 형태였던 텐서를 .view(1,-1) 해주면 1x6의 형태로 바뀝니다. .view(3,-1)이면 3x2로 바뀜.\n",
    "                                                                                # 만약 전체 텐서의 크기가 batch_size로 나누어 떨어지지 않으면 오류가 납니다.\n",
    "        out = self.fc_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fDPJnQS8gO8y"
   },
   "source": [
    "### 2) 손실함수 & 최적화함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4983,
     "status": "ok",
     "timestamp": 1566788924013,
     "user": {
      "displayName": "Gunho Choi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBSqM0cFU5ZceEDo5gH8hXfSGh8z5BVTu5HgREceg=s64",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "fZ56zT9PgO8y",
    "outputId": "025ef734-be23-4659-88f0-179c467084a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# gpu가 사용 가능한 경우에는 device를 gpu로 설정하고 불가능하면 cpu로 설정합니다.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# 모델을 지정한 장치로 올립니다.\n",
    "model = CNN().to(device)\n",
    "\n",
    "# 손실함수로는 크로스엔트로피를 사용합니다.\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화함수로는 Adam을 사용합니다.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P5DHl_cOgO82"
   },
   "source": [
    "## 4. 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "1\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "2\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "3\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "4\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "5\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "6\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "7\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "8\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "9\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "10\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "11\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "12\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "13\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "14\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "15\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "16\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "17\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "18\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "19\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "20\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "21\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "22\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "23\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "24\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "25\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "26\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "27\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "28\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "29\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "30\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "31\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "32\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "33\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "34\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "35\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "36\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "37\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "38\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "39\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "40\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "41\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "42\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "43\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "44\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "45\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "46\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "47\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "48\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "49\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "50\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "51\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "52\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "53\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "54\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "55\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "56\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "57\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "58\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "59\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "60\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "61\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "62\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "63\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "64\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "65\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "66\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "67\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "68\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "69\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "70\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "71\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "72\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "73\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "74\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "75\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "76\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "77\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "78\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "79\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "80\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "81\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "82\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "83\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "84\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "85\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "86\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "87\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "88\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "89\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "90\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "91\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "92\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "93\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "94\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "95\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "96\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "97\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "98\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "99\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "100\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "101\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "102\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "103\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "104\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "105\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "106\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "107\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "108\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "109\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "110\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "111\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "112\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "113\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "114\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "115\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "116\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "117\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "118\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "119\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "120\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "121\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "122\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "123\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "124\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "125\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "126\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "127\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "128\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "129\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "130\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "131\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "132\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "133\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "134\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "135\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "136\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "137\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "138\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "139\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "140\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "141\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "142\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "143\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "144\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "145\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "146\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "147\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "148\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "149\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "150\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "151\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "152\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "153\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "154\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "155\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "156\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "157\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "158\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "159\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "160\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "161\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "162\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "163\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "164\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "165\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "167\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "168\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "169\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "170\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "171\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "172\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "173\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "174\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "175\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "176\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "177\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "178\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "179\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "180\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "181\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "182\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "183\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "184\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "185\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "186\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "187\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "188\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "189\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "190\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "191\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "192\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "193\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "194\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "195\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "196\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "197\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "198\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "199\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "200\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "201\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "202\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "203\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "204\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "205\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "206\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "207\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "208\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "209\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "210\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "211\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "212\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "213\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "214\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "215\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "216\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "217\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "218\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "219\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "220\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "221\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "222\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "223\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "224\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "225\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "226\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "227\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "228\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "229\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "230\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "231\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "232\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "233\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for j,[image,label] in enumerate(train_loader):\n",
    "    print(j)\n",
    "    print(image.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43600,
     "status": "ok",
     "timestamp": 1566788999187,
     "user": {
      "displayName": "Gunho Choi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBSqM0cFU5ZceEDo5gH8hXfSGh8z5BVTu5HgREceg=s64",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "AtsQ3UHzgO83",
    "outputId": "9487e74f-4719-4094-c593-31bd2891198d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<built-in method size of Tensor object at 0x0000017EDF8F39A8>\n",
      "<built-in method size of Tensor object at 0x0000017EDF8F3908>\n",
      "tensor(2.3058, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-23ad988c0ea3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0my_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_arr =[]\n",
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        \n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 1000 == 0:\n",
    "            print(j)\n",
    "            print(image.size)\n",
    "            print(label.size)\n",
    "            print(loss)\n",
    "            loss_arr.append(loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YG6Q37ogO87"
   },
   "outputs": [],
   "source": [
    "#param_list = list(model.parameters())\n",
    "#print(param_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oy_VtVa0gO8-"
   },
   "source": [
    "## 5. 학습시 손실 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1142,
     "status": "ok",
     "timestamp": 1566789006096,
     "user": {
      "displayName": "Gunho Choi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBSqM0cFU5ZceEDo5gH8hXfSGh8z5BVTu5HgREceg=s64",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "_OZvoJA9gO9B",
    "outputId": "996bc0bd-3676-489f-ef55-69ec46a44585"
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1pXaYCUXgO9F"
   },
   "source": [
    "## 6. 테스트 데이터 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1951,
     "status": "ok",
     "timestamp": 1566789092259,
     "user": {
      "displayName": "Gunho Choi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBSqM0cFU5ZceEDo5gH8hXfSGh8z5BVTu5HgREceg=s64",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "l3buWYkSgO9I",
    "outputId": "a2908ed5-79dc-4f9c-8e58-773292aa3123"
   },
   "outputs": [],
   "source": [
    "# 맞은 개수, 전체 개수를 저장할 변수를 지정합니다.\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 인퍼런스 모드를 위해 no_grad 해줍니다.\n",
    "with torch.no_grad():\n",
    "    # 테스트로더에서 이미지와 정답을 불러옵니다.\n",
    "    for image,label in test_loader:\n",
    "        print(image.shape)\n",
    "        print(label.shape)\n",
    "        # 두 데이터 모두 장치에 올립니다.\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "\n",
    "        # 모델에 데이터를 넣고 결과값을 얻습니다.\n",
    "        output = model.forward(x)\n",
    "        \n",
    "        # https://pytorch.org/docs/stable/torch.html?highlight=max#torch.max\n",
    "        # torch.max를 이용해 최대 값 및 최대값 인덱스를 뽑아냅니다.\n",
    "        # 여기서는 최대값은 필요없기 때문에 인덱스만 사용합니다.\n",
    "        _,output_index = torch.max(output,1)\n",
    "        \n",
    "        # 전체 개수는 라벨의 개수로 더해줍니다.\n",
    "        # 전체 개수를 알고 있음에도 이렇게 하는 이유는 batch_size, drop_last의 영향으로 몇몇 데이터가 잘릴수도 있기 때문입니다.\n",
    "        total += label.size(0)\n",
    "        \n",
    "        # 모델의 결과의 최대값 인덱스와 라벨이 일치하는 개수를 correct에 더해줍니다.\n",
    "        correct += (output_index == y_).sum().float()\n",
    "    \n",
    "    # 테스트 데이터 전체에 대해 위의 작업을 시행한 후 정확도를 구해줍니다.\n",
    "    print(\"Accuracy of Test Data: {}%\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M88c7tkAaANZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5.6 기본적인 합성곱 신경망 실습.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
